import pandas as pd
import warnings
warnings.filterwarnings("ignore")
from datetime import datetime, timedelta
import numpy as np
from sklearn.preprocessing import OrdinalEncoder
import matplotlib.pyplot as plt
import plotly as px
import seaborn as sns
ExcelFile =r"C:\Users\Dell\JupyterPythoncodes\Copper_Set.xlsx"
excelFile = pd.read_excel (ExcelFile)
excelFile.to_csv ("ResultCopperFile.csv", index = None, header=True)
df = pd.DataFrame(pd.read_csv("ResultCopperFile.csv"))
df
df.info()
  df.isnull().sum()

  for i in df.columns:
    print(i,":",df[i].nunique())

  df.dtypes
#converting the datatypes
# item_date, delivery date, quantity tons

df["quantity tons"]= pd.to_numeric(df["quantity tons"],errors="coerce")
df["item_date_1"]= pd.to_datetime(df["item_date"],format="%Y%m%d",errors="coerce").dt.date
df["delivery_date_1"]= pd.to_datetime(df["delivery date"],format="%Y%m%d",errors="coerce").dt.date
df.info()
df.isnull().sum()
#removing the "00000" datas in the "material_ref" column
df["material_ref"]=df["material_ref"].apply(lambda x: np.nan if str(x).startswith("00000") else x)
df.isnull().sum()
# "material_ref" have a maximum null values (55%) so, we want to drop the column
# And id is a unique values so we want to drop the column

df.drop(columns=["id","material_ref"],inplace=True)
df.isnull().sum()
df.describe().T
#quantity tons and selling_price have a negative values, This is impossible,
# so we need to replace the negative values

#converting the negative values into the null values
df["quantity tons"]= df["quantity tons"].apply(lambda x: np.nan if x<=0 else x)
df["selling_price"]= df["selling_price"].apply(lambda x: np.nan if x<=0 else x)
df.nunique()
df.isnull().sum()
# object columns and mode method
df["item_date_1"].fillna(df["item_date_1"].mode().iloc[0],inplace=True)
df["delivery_date_1"].fillna(df["delivery_date_1"].mode().iloc[0],inplace=True)
df["status"].fillna(df["status"].mode().iloc[0],inplace=True)
df["item_date"]. fillna(df["item_date"].mode().iloc[0],inplace=True)
df["delivery date"]. fillna(df["delivery date"].mode().iloc[0],inplace=True)
df.isnull().sum()
#numarical column and median()
df["quantity tons"].fillna(df["quantity tons"].median(),inplace=True)
df["customer"].fillna(df["customer"].median(),inplace=True)
df["country"].fillna(df["country"].median(),inplace=True)
df["application"].fillna(df["application"].median(),inplace=True)
df["thickness"].fillna(df["thickness"].median(),inplace=True)
df["selling_price"].fillna(df["selling_price"].median(),inplace=True)
df.isnull().sum()
df.head()
df["status"].unique()
df["status"]= df["status"].map({'Won':1, 'Draft':2, 'To be approved':3, 'Lost':0, 'Not lost for AM':4,
                                'Wonderful':5, 'Revised':6, 'Offered':7, 'Offerable':8})
df["status"].unique()
df["item type"]= OrdinalEncoder().fit_transform(df[["item type"]])
df["item type"].unique()
df.describe().T
df.to_csv("Industrial_Copper_proper.csv",index= False)
# detecting the skewed columns using plot
def plot(df,column):
    
  #distplot
    plt.figure(figsize=(15,4))
    plt.subplot(1,3,1)
    sns.distplot(df[column])
    plt.title("distplot for"+" "+column)

  #histogram plot

    plt.subplot(1,3,2)
    sns.histplot(df, x= column, kde= True, bins=30,color="salmon")
    plt.title("histogram plot for"+" "+column)

  #boxplot

    plt.subplot(1,3,3)
    sns.boxplot(df, x=column)
    plt.title("Box plot for"+" "+column)
skewed_columns=['quantity tons', 'customer', 'country', 'status',
                'item type', 'application', 'thickness', 'width', 'product_ref',
                'selling_price']
for i in skewed_columns:
    plot(df,i)
      #Skewed columns:
# 1.quantity tons
# 2.customer
# 3.thickness
# 4.selling_price
df1= df.copy()
df1.columns
Index(['item_date', 'quantity tons', 'customer', 'country', 'status',
       'item type', 'application', 'thickness', 'width', 'product_ref',
       'delivery date', 'selling_price', 'item_date_1', 'delivery_date_1'],
      dtype='object')
df1["quantity_tons_log"]= np.log(df1["quantity tons"])
df1["customer_log"]= np.log(df1["customer"])
df1["thickness_log"]= np.log(df1["thickness"])
df1["selling_price_log"]= np.log(df1["selling_price"])
skewed_columns_2=["quantity_tons_log","customer_log","thickness_log","selling_price_log"]
for i in skewed_columns_2:
    plot(df1,i)

df2= df1.copy()
df2.head()
  def outlier(df,column):
    q1= df[column].quantile(0.25)
    q3= df[column].quantile(0.75)

    iqr= q3-q1

    upper_threshold= q3 + (1.5*iqr)
    lower_threshold= q1 - (1.5*iqr)

    df[column]= df[column].clip(lower_threshold, upper_threshold)
# (Ex: lower threshold = 5 and upper threshold = 20)
# above upper threshold values (>20) are converted to upper threshold value (20) in features
# below lower threshold values (<5)  are converted to lower threshold value (5)  in features
df2.describe().T
  df2.columns
Index(['item_date', 'quantity tons', 'customer', 'country', 'status',
       'item type', 'application', 'thickness', 'width', 'product_ref',
       'delivery date', 'selling_price', 'item_date_1', 'delivery_date_1',
       'quantity_tons_log', 'customer_log', 'thickness_log',
       'selling_price_log'],
      dtype='object')
outlier_columns= ['quantity_tons_log', 'customer_log', 'thickness_log','selling_price_log','width','application']
for i in outlier_columns:
    outlier(df2,i)
df2.describe().T
for i in outlier_columns:
    plot(df2,i)
#Droping the unwanted skewed columns
#Skewed columns:
# 1.quantity tons
# 2.customer
# 3.thickness
# 4.selling_price

df3= df2.drop(columns=["quantity tons","customer","thickness","selling_price"])
df3.head()
#Checking the correlation with using the heatmap

corr= df3.drop(columns=["item_date","delivery date","item_date_1","delivery_date_1"]).corr()
plt.figure(figsize=(10,3))
sns.heatmap(corr, annot= True, fmt="0.2f")
plt.show()
df4= df3.copy()
df4.head()
df4.dtypes
#converting the datatype (object to datetime format)
df4["delivery_date_1"]= pd.to_datetime(df4["delivery_date_1"])
df4["item_date_1"]= pd.to_datetime(df4["item_date_1"])
#identifying the difference of the "delivery date" and the "item date"
df4["date_differ"]= (df4["delivery_date_1"]-df4["item_date_1"]).dt.days
df4["date_differ"]
# some values have a negative values
# it's mean the "delivery date provides , the previous date then the "item date"
# so this is not possible , so we want to predic the delivery date for the some datas
#creating the another 3 columns using the "item_date_1"
# it is usefull for the delivery date prediction
df4["item_date_day"]= df4["item_date_1"].dt.day
df4["item_date_month"]= df4["item_date_1"].dt.month
df4["item_date_year"]= df4["item_date_1"].dt.year
df4.head()
#separating the posive values(pv) dataframe and negative values(nv) dataframe based on the "date_differ" column
df4_pv= df4[df4["date_differ"]>=0]
df4_pv.reset_index(drop= True, inplace= True)
df4_pv.tail()
df4_nv= df4[df4["date_differ"]<0]
df4_nv.reset_index(drop= True, inplace= True)
df4_nv.tail()
# now we want to create the model for delivery date prediction
# importing the model
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import ExtraTreesRegressor
from sklearn.ensemble import GradientBoostingRegressor
from xgboost import XGBRegressor
df4_pv.columns
#Find the best algorithm for the "delivery date" prediction

def accuracy_date_prediction(df, algorithm):
    x= df.drop(columns=["item_date_1", "delivery_date_1", "date_differ"])
    y= df["date_differ"]

    #train test splitting
    x_train, x_test, y_train, y_test= train_test_split(x,y, test_size= 0.2, random_state=42)

    model= algorithm().fit(x_train,y_train)
    y_pred= model.predict(x_test)

    #checking the accuracy score
    mse= mean_squared_error(y_test, y_pred)
    rmse= np.sqrt(mse)
    mae= mean_absolute_error(y_test,y_pred)
    r2= r2_score(y_test, y_pred)

    metrics={"R2_score":r2,
           "Mean_squared_error":mse,
           "Root_mean_squared_error":rmse,
           "Mean_absolute_error":mae,
           }
    return metrics
print(accuracy_date_prediction(df4_pv,DecisionTreeRegressor))
print(accuracy_date_prediction(df4_pv,RandomForestRegressor))
print(accuracy_date_prediction(df4_pv,ExtraTreesRegressor))
print(accuracy_date_prediction(df4_pv,GradientBoostingRegressor))
print(accuracy_date_prediction(df4_pv,AdaBoostRegressor))
print(accuracy_date_prediction(df4_pv,XGBRegressor))
# Random Forest algorithm is low bias and reduce overfitting compared to others.
# Model for the RandomForest

def RandomForest(train_df, test_df):

    x= train_df.drop(columns=["item_date_1", "delivery_date_1", "date_differ"])
    y= train_df["date_differ"]

    #train test splitting
    x_train, x_test, y_train, y_test= train_test_split(x,y, test_size= 0.2, random_state=42)
    model= RandomForestRegressor().fit(x_train, y_train)

    data= test_df.drop(columns=["item_date_1", "delivery_date_1", "date_differ"])

    y_pred=model.predict(data)

    return y_pred
date_difference= RandomForest(df4_pv,df4_nv)
date_difference
# changing the "date_differ" datatype float into int
date_difference_1= []
for i in date_difference:
    dd= int(round(i,0))
    date_difference_1.append(dd)
df4_nv["date_differ"]= pd.DataFrame(date_difference_1)
df4_nv.isnull().sum()
#find the delivery date using "item_date_1" and "date_differ"

def find_delivery_date(item_date, date_differ):
    date= item_date + pd.to_timedelta(date_differ,unit= "D")
    return date
df4_nv["delivery_date_1"]= find_delivery_date(df4_nv["item_date_1"],df4_nv["date_differ"])
# Concadinating the two dataframes(df4_pv,df4_nv) based on the rows
df_final=pd.concat([df4_pv,df4_nv],axis=0,ignore_index=True)
df_final.tail()
# Now we create the three new columns using the "delivery_date_1"
df_final['delivery_date_day']= df_final["delivery_date_1"].dt.day
df_final['delivery_date_month']= df_final["delivery_date_1"].dt.month
df_final['delivery_date_year']= df_final["delivery_date_1"].dt.year
df_final.head(2)
# Droping the unwanted columns
df_final.drop(columns=["item_date","delivery date","item_date_1","delivery_date_1","date_differ"],inplace=True)
df_final.columns
#packages
from sklearn.model_selection import train_test_split,GridSearchCV
from sklearn.metrics import accuracy_score,auc,roc_curve,confusion_matrix,classification_report

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier

from imblearn.combine import SMOTETomek

import pickle
df_class= df_final.copy()
  # filter the status column only want to be a (won& loss)
df_c= df_class[(df_class["status"] == 1) | (df_class["status"] == 0)]
df_c.tail()
  # find the best algorithm for the classification prediction

def accuracy_checking(x_data, y_data, algorithm):
    #train test splitting
    x_train, x_test, y_train, y_test= train_test_split(x_data, y_data, test_size= 0.2, random_state=42)

    model= algorithm().fit(x_train, y_train)

    y_pred_train= model.predict(x_train)
    y_pred_test= model.predict(x_test)

    #checking the accuracy_score
    accuracy_train= accuracy_score(y_train, y_pred_train)
    accuracy_test= accuracy_score(y_test, y_pred_test)

    metrics={"Algorithm": algorithm.__name__,
           "Accuracy_Train": accuracy_train,
           "Accuracy_Test": accuracy_test}
    return metrics
print(accuracy_checking(x,y,DecisionTreeClassifier))
print(accuracy_checking(x,y,RandomForestClassifier))
print(accuracy_checking(x,y,ExtraTreesClassifier))
print(accuracy_checking(x,y,AdaBoostClassifier))
print(accuracy_checking(x,y,GradientBoostingClassifier))
print(accuracy_checking(x,y,XGBClassifier))
